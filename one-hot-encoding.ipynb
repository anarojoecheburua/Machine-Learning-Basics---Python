{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Implementing One-Hot Encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Python offers powerful libraries like Pandas and Scikit-learn, which provide convenient and efficient ways to perform one-hot encoding. \n",
    "\n",
    "In this notebook, we'll walk through the step-by-step process of applying one-hot encoding using these libraries. We'll start with Pandas' `get_dummies()` function, which is quick and easy for straightforward encoding tasks. Then, we'll explore Scikit-learn's `OneHotEncoder`, which offers more flexibility and control, particularly useful for more complex encoding needs. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Pandas  `get_dummies()`\n",
    "Pandas provides a very convenient function, `get_dummies()`, to create one-hot encoded columns directly from a DataFrame.\n",
    "\n",
    "Here's how you can use it:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Color_Blue  Color_Green  Color_Red\n",
      "0           0            0          1\n",
      "1           0            1          0\n",
      "2           1            0          0\n",
      "3           0            0          1\n"
     ]
    }
   ],
   "source": [
    "# Sample data\n",
    "data = {'Color': ['Red', 'Green', 'Blue', 'Red']}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Applying one-hot encoding\n",
    "df_encoded = pd.get_dummies(df)\n",
    "\n",
    "# Displaying the encoded DataFrame\n",
    "print(df_encoded)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we import the Pandas library, which provides powerful data manipulation and analysis tools. Then,we create a dictionary `data` with a single key `'Color'` and a list of color names as values. We then convert this dictionary into a Pandas DataFrame `df`.\n",
    "\n",
    "We use the `pd.get_dummies()` function to apply one-hot encoding to the DataFrame `df`. This function automatically detects the categorical column(s) and creates new binary columns for each unique category.\n",
    "\n",
    "Finally, we print the encoded DataFrame to see the result.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Scikit-learn's OneHotEncoder\n",
    "\n",
    "For more flexibility and control over the encoding process, Scikit-learn offers the `OneHotEncoder` class. This class provides advanced options, such as handling unknown categories and fitting the encoder to the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 1.]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# Creating the encoder\n",
    "enc = OneHotEncoder(handle_unknown='ignore')\n",
    "\n",
    "# Sample data\n",
    "X = [['Red'], ['Green'], ['Blue']]\n",
    "\n",
    "# Fitting the encoder to the data\n",
    "enc.fit(X)\n",
    "\n",
    "# Transforming new data\n",
    "result = enc.transform([['Red']]).toarray()\n",
    "\n",
    "# Displaying the encoded result\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We import the `OneHotEncoder` class from Scikit-learn and  NumPy. After this, we create an instance of OneHotEncoder. The` handle_unknown='ignore'` parameter tells the encoder to ignore unknown categories (categories that were not seen during the fitting process) during the transformation. We then create a list of lists `X`, where each inner list contains a single color. This is the data we will fit the encoder to.\n",
    "\n",
    "We fit the encoder to the sample data `X`. During this step, the encoder learns the unique categories present in the data. We use the fitted encoder to transform new data. In this case, we transform a single color 'Red'. The `transform()` method returns a sparse matrix, which we convert to a dense array using the `toarray()` method. \n",
    "\n",
    "This indicates that 'Red' is present (1) and 'Green' and 'Blue' are absent (0).\n",
    "Finally, we print the result to see the one-hot encoded representation of 'Red'.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handling Categorical Features with Many Unique Values\n",
    "One significant challenge with one-hot encoding is the \"curse of dimensionality.\" This occurs when a categorical feature has a large number of unique values, leading to an explosion in the number of columns. This can make the dataset sparse and computationally expensive to process. \n",
    "\n",
    "In order to overcome this, there are some techniques that can be applied.\n",
    "\n",
    "### Feature Hashing\n",
    "Feature hashing, also known as the hashing trick, can help reduce dimensionality by hashing categories into a fixed number of columns. This approach maintains efficiency while controlling the number of features. Here is an example on how to do this:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hashed Features DataFrame:\n",
      "   Feature1  Feature2  Feature3\n",
      "0       1.0       2.0       0.0\n",
      "1       0.0       3.0       0.0\n",
      "2       0.0       2.0       0.0\n",
      "3       1.0       2.0       0.0\n",
      "4      -1.0       1.0       2.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction import FeatureHasher\n",
    "import pandas as pd\n",
    "\n",
    "# Sample data\n",
    "data = {'Color': ['Red', 'Green', 'Blue', 'Red', 'Yellow']}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Initialize FeatureHasher\n",
    "hasher = FeatureHasher(n_features=3, input_type='string')\n",
    "\n",
    "# Apply feature hashing\n",
    "hashed_features = hasher.transform(df['Color'])\n",
    "hashed_df = pd.DataFrame(hashed_features.toarray(), columns=['Feature1', 'Feature2', 'Feature3'])\n",
    "\n",
    "# Display the hashed features DataFrame\n",
    "print(\"Hashed Features DataFrame:\")\n",
    "print(hashed_df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We import the necessary libraries, including` FeatureHasher` from `sklearn.feature_extraction` and pandas. We then create a DataFrame with a categorical feature` 'Color'`.\n",
    "\n",
    "We initialize FeatureHasher with the desired number of output features (n_features=3) and specify the input type as `'string'`. After that, we apply the transform method to the `'Color'` column and convert the resulting sparse matrix to a dense array, which is then converted to a DataFrame. Finally, we print the DataFrame containing the hashed features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dimensionality Reduction\n",
    "After one-hot encoding, techniques like Principal Component Analysis (PCA) can be applied to reduce the number of dimensions while preserving the essential information in the dataset. PCA can help compress the high-dimensional data into a lower-dimensional space, making it more manageable for machine learning algorithms.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PCA-Transformed DataFrame:\n",
      "      PCA1          PCA2\n",
      "0  0.69282 -0.000000e+00\n",
      "1 -0.46188  7.071068e-01\n",
      "2 -0.46188 -5.551115e-17\n",
      "3  0.69282 -1.110223e-16\n",
      "4 -0.46188 -7.071068e-01\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.decomposition import PCA\n",
    "import pandas as pd\n",
    "\n",
    "# Sample data\n",
    "data = {'Color': ['Red', 'Green', 'Blue', 'Red', 'Yellow']}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Applying one-hot encoding\n",
    "encoder = OneHotEncoder(sparse=False)\n",
    "one_hot_encoded = encoder.fit_transform(df[['Color']])\n",
    "\n",
    "# Creating a DataFrame with one-hot encoded columns\n",
    "# Check if get_feature_names_out is available\n",
    "if hasattr(encoder, 'get_feature_names_out'):\n",
    "    feature_names = encoder.get_feature_names_out(['Color'])\n",
    "else:\n",
    "    feature_names = [f'Color_{cat}' for cat in encoder.categories_[0]]\n",
    "\n",
    "df_encoded = pd.DataFrame(one_hot_encoded, columns=feature_names)\n",
    "\n",
    "# Initialize PCA\n",
    "pca = PCA(n_components=2)  # Adjust the number of components based on your needs\n",
    "\n",
    "# Apply PCA\n",
    "pca_transformed = pca.fit_transform(df_encoded)\n",
    "\n",
    "# Creating a DataFrame with PCA components\n",
    "df_pca = pd.DataFrame(pca_transformed, columns=['PCA1', 'PCA2'])\n",
    "\n",
    "# Display the PCA-transformed DataFrame\n",
    "print(\"PCA-Transformed DataFrame:\")\n",
    "print(df_pca)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We import the necessary libraries, including pandas, `OneHotEncoder` from sklearn.preprocessing, and `PCA` from `sklearn.decomposition`. We then create a DataFrame with a categorical feature `'Color'`.\n",
    "\n",
    "We use `OneHotEncoder` to convert the categorical feature into a one-hot encoded format. The result is a DataFrame with binary columns for each category.\n",
    "After that, we initialize PCA with the desired number of components (n_components=2) and apply it to the one-hot encoded data. The result is a transformed DataFrame with two principal components. Finally, we print the DataFrame containing the PCA-transformed features.\n",
    "PCA helps to reduce the dimensionality of the one-hot encoded data, making it more manageable while preserving essential information. This approach is particularly useful when dealing with high-dimensional data resulting from one-hot encoding.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Best Practices and Considerations\n",
    "Implementing one-hot encoding effectively requires attention to several best practices and considerations to ensure optimal performance and accuracy of your machine learning models. While one-hot encoding is a powerful tool, improper implementation can lead to issues such as multicollinearity or inefficiency in handling new data.\n",
    "\n",
    "### Handling Unknown Categories\n",
    "When deploying machine learning models, it is common to encounter categories in the test set that were not present in the training set. Scikit-learn's `OneHotEncoder` can handle unknown categories by ignoring them or assigning them to a dedicated column, ensuring the model can still process new data effectively.\n",
    "\n",
    "This example demonstrates how to fit the encoder on the training data and then transform both training and test data, including handling categories that were not present in the training set.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoded training data:\n",
      "[[0. 0. 1.]\n",
      " [0. 1. 0.]\n",
      " [1. 0. 0.]]\n",
      "Encoded test data:\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 0.]\n",
      " [1. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import numpy as np\n",
    "\n",
    "# Training data\n",
    "X_train = [['Red'], ['Green'], ['Blue']]\n",
    "\n",
    "# Creating the encoder with handle_unknown='ignore'\n",
    "enc = OneHotEncoder(handle_unknown='ignore')\n",
    "\n",
    "# Fitting the encoder to the training data\n",
    "enc.fit(X_train)\n",
    "\n",
    "# Transforming the training data\n",
    "X_train_encoded = enc.transform(X_train).toarray()\n",
    "print(\"Encoded training data:\")\n",
    "print(X_train_encoded)\n",
    "\n",
    "# Test data with an unknown category 'Yellow'\n",
    "X_test = [['Red'], ['Yellow'], ['Blue']]\n",
    "\n",
    "# Transforming the test data\n",
    "X_test_encoded = enc.transform(X_test).toarray()\n",
    "print(\"Encoded test data:\")\n",
    "print(X_test_encoded)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example, the encoder is fitted on the training data, learning the categories 'Red', 'Green', and 'Blue'. When transforming the test data, it encounters 'Yellow', which was not seen during training. Since we set `handle_unknown='ignore'`, the encoder produces a row of zeros for 'Yellow', effectively ignoring the unknown category.\n",
    "\n",
    "Handling unknown categories in this way, we can ensure that your model can process new data effectively, even if it contains previously unseen categories."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dropping the Original Column\n",
    "After applying one-hot encoding, it is crucial to drop the original categorical column from the dataset. Keeping the original column can lead to multicollinearity, where redundant information affects the model's performance. Ensure that each category is represented only once in the dataset to maintain its integrity.\n",
    "\n",
    "Here's how you can drop the original categorical column after applying one-hot encoding to avoid multicollinearity and ensure that each category is represented only once in the dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoded DataFrame:\n",
      "   Color_Blue  Color_Green  Color_Red\n",
      "0       False        False       True\n",
      "1       False         True      False\n",
      "2        True        False      False\n",
      "3       False        False       True\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Sample data\n",
    "data = {'Color': ['Red', 'Green', 'Blue', 'Red']}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Applying one-hot encoding\n",
    "df_encoded = pd.get_dummies(df, columns=['Color'])\n",
    "\n",
    "# Displaying the encoded DataFrame\n",
    "print(\"Encoded DataFrame:\")\n",
    "print(df_encoded)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
